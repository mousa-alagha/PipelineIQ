{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5cb121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Prepared 720 chunks from 12 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/gvx_50_d2ld80tzps8pyy0wc0000gn/T/ipykernel_90739/2096901392.py:37: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  emb = OpenAIEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Vector store saved to: /Users/mousa/Desktop/PipelineIQ/vectorstore\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell: Ingest PDFs ‚Üí FAISS vectorstore\n",
    "from dotenv import load_dotenv\n",
    "import os, json\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# embeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# vector store\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "# 1. Load API key\n",
    "load_dotenv()\n",
    "\n",
    "# 2. Paths\n",
    "DATA_DIR = \"/Users/mousa/Desktop/PipelineIQ/data/raw_documents\"\n",
    "META_PATH = \"/Users/mousa/Desktop/PipelineIQ/data/metadata.json\"\n",
    "STORE_DIR = \"/Users/mousa/Desktop/PipelineIQ/vectorstore\"\n",
    "\n",
    "# 3. Read metadata\n",
    "with open(META_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    docs = json.load(f)\n",
    "\n",
    "# 4. Extract & chunk text\n",
    "all_texts, all_meta = [], []\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "for doc in docs:\n",
    "    path = os.path.join(DATA_DIR, doc[\"filename\"])\n",
    "    reader = PdfReader(path)\n",
    "    text = \"\".join(page.extract_text() or \"\" for page in reader.pages)\n",
    "    chunks = splitter.split_text(text)\n",
    "    all_texts.extend(chunks)\n",
    "    all_meta.extend([{\"title\": doc[\"title\"], \"source\": doc[\"filename\"]}] * len(chunks))\n",
    "\n",
    "print(f\"> Prepared {len(all_texts)} chunks from {len(docs)} documents.\")\n",
    "\n",
    "# 5. Embed & build FAISS index\n",
    "emb = OpenAIEmbeddings()\n",
    "index = FAISS.from_texts(all_texts, emb, metadatas=all_meta)\n",
    "\n",
    "# 6. Save locally\n",
    "os.makedirs(STORE_DIR, exist_ok=True)\n",
    "index.save_local(STORE_DIR)\n",
    "print(f\"> Vector store saved to: {STORE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882920b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Answer:\n",
      " The primary function of a blowout preventer is to prevent blowouts by sealing the wellbore. \n",
      "SOURCES: Blowout-Preventers-1.pdf, Oil and gas production handbook ed3x0_web.pdf\n",
      "\n",
      "üìù Summary:\n",
      " - Blowout preventers are designed to prevent blowouts by sealing the wellbore\n",
      "- They are a crucial safety device in oil and gas production\n",
      "- The information is sourced from Blowout-Preventers-1.pdf and Oil and gas production handbook ed3x0_web.pdf\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# 1) Load index\n",
    "VECTORSTORE_DIR = \"/Users/mousa/Desktop/PipelineIQ/vectorstore\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "index = FAISS.load_local(\n",
    "    VECTORSTORE_DIR,\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# 2) Build QA chain\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "qa_chain = load_qa_with_sources_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "# 3) Ask a question\n",
    "question = \"What is the primary function of a blowout preventer?\"\n",
    "docs = index.similarity_search(question, k=3)\n",
    "result = qa_chain({\"input_documents\": docs, \"question\": question})\n",
    "print(\"ü§ñ Answer:\\n\", result[\"output_text\"])\n",
    "\n",
    "# 4) Summarize with a HumanMessage\n",
    "summary_msg = llm([HumanMessage(content=f\"Summarize this answer in 3 bullet points:\\n\\n{result['output_text']}\")])\n",
    "print(\"\\nüìù Summary:\\n\", summary_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46bb9757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 chunks:\n",
      "Chunk 1: This is a sample text to demonstrate the\n",
      "Chunk 2: the RecursiveCharacterTextSplitter functionality.\n",
      "Chunk 3: It splits text into chunks based on the specified\n",
      "Chunk 4: specified chunk size and overlap.\n"
     ]
    }
   ],
   "source": [
    "# Example usage of RecursiveCharacterTextSplitter\n",
    "sample_text = \"This is a sample text to demonstrate the RecursiveCharacterTextSplitter functionality. It splits text into chunks based on the specified chunk size and overlap.\"\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "chunks = splitter.split_text(sample_text)\n",
    "\n",
    "print(f\"Generated {len(chunks)} chunks:\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"Chunk {i}: {chunk}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
